{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow, sklearn, matplotlib, numpy and pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import requests\n",
    "import json\n",
    "import pywhatkit\n",
    "\n",
    "from datetime import timedelta\n",
    "from matplotlib import pyplot\n",
    "from pickle import dump\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#configure pandas to show the full dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function that takes input in radians and returns sin + cos of that input\n",
    "def sin_cos(x, mode):\n",
    "    denom = 2*math.pi\n",
    "\n",
    "    if mode == 'hour':\n",
    "        return math.sin((int(x)/24)*denom) + math.cos((int(x)/24)*denom)\n",
    "    elif mode == 'day':\n",
    "        return math.sin((int(x)/31)*denom) + math.cos((int(x)/31)*denom)\n",
    "    else:\n",
    "        return math.sin((int(x)/12)*denom) + math.cos((int(x)/12)*denom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to merge dataset_AQI and dataset_Weather on their indices\n",
    "def merge_datasets(dataset_AQI, dataset_Weather):\n",
    "    #join the two dataframes on their indices\n",
    "    dataset_merged = dataset_AQI.join(dataset_Weather, how='inner')\n",
    "    #dataset_AQI.merge(dataset_Weather, left_index=True, right_index=True)\n",
    "    return dataset_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that takes 12 hour time and converts it to 24 hour time\n",
    "def convert24(str1):\n",
    "\n",
    "    str1 = str(str1)\n",
    "      \n",
    "    # Checking if last two elements of time\n",
    "    # is AM and first two elements are 12\n",
    "    if str1[-2:] == \"AM\" and str1[:2] == \"12\":\n",
    "        return \"00\" + str1[2:-2]\n",
    "          \n",
    "    # remove the AM    \n",
    "    elif str1[-2:] == \"AM\":\n",
    "        return str1[:-2]\n",
    "      \n",
    "    # Checking if last two elements of time\n",
    "    # is PM and first two elements are 12   \n",
    "    elif str1[-2:] == \"PM\" and str1[:2] == \"12\":\n",
    "        return str1[:-2]\n",
    "          \n",
    "    else:  \n",
    "        # add 12 to hours and remove PM\n",
    "        return str(int(str1[:2]) + 12) + str1[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function that converts degrees to radians\n",
    "def deg2rad(deg):\n",
    "    return math.sin(deg * (math.pi/180)) + math.cos(deg * (math.pi/180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset city_hour.csv into a dataframe dataset\n",
    "dataset_AQI = pd.read_csv('city_hour.csv')\n",
    "\n",
    "#import dataset delhi.csv into a dataframe with date_time as index\n",
    "dataset_Weather = pd.read_csv('delhi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NaN values in all columns with interpolation\n",
    "dataset_AQI['PM2.5'] = dataset_AQI['PM2.5'].interpolate()\n",
    "\n",
    "#remove rows where all columns are NaN\n",
    "dataset_AQI = dataset_AQI.dropna()\n",
    "\n",
    "#give the number of NaN values in dataset\n",
    "dataset_AQI.isnull().sum()\n",
    "\n",
    "#give size of dataset_AQI\n",
    "dataset_AQI.shape\n",
    "\n",
    "#make a new dataframe where the City column is 'Gurugram'\n",
    "dataset_AQI = dataset_AQI[dataset_AQI['City'] == 'Delhi']\n",
    "\n",
    "#rename dataset_Weather column date_time to Datetime\n",
    "dataset_Weather.rename(columns={'date_time':'Datetime'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set index of dataset_Weather to Datetime\n",
    "dataset_Weather.set_index('Datetime', inplace=True)\n",
    "dataset_Weather.index = dataset_Weather.index.astype(str)\n",
    "\n",
    "#set index of dataset_AQI to Datetime\n",
    "dataset_AQI.set_index('Datetime', inplace=True)\n",
    "dataset_AQI.index = dataset_AQI.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two datasets\n",
    "dataset_AQI_Weather = merge_datasets(dataset_Weather, dataset_AQI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_columns = ['totalSnow_cm', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3','Benzene', 'Toluene', 'Xylene', 'AQI_Bucket', 'City', 'moonrise', 'moonset', 'moon_illumination', 'HeatIndexC', 'WindChillC', 'uvIndex']\n",
    "#drop columns from dataset_AQI_Weather that are in rem_columns\n",
    "dataset_AQI_Weather.drop(rem_columns, axis=1, inplace=True)\n",
    "\n",
    "#remove all space in columns 'sunrise', 'sunset'\n",
    "dataset_AQI_Weather['sunrise'] = dataset_AQI_Weather['sunrise'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "dataset_AQI_Weather['sunset'] = dataset_AQI_Weather['sunset'].apply(lambda x: x.replace(\" \",\"\"))\n",
    "\n",
    "#Convert columns 'sunrise', 'sunset' using convert24 funnction\n",
    "dataset_AQI_Weather['sunrise'] = dataset_AQI_Weather['sunrise'].apply(convert24)\n",
    "dataset_AQI_Weather['sunset'] = dataset_AQI_Weather['sunset'].apply(convert24)\n",
    "\n",
    "#convert 'sunrise', 'sunset' to seconds\n",
    "dataset_AQI_Weather['sunrise'] = dataset_AQI_Weather['sunrise'].apply(lambda x: (int(x[:2])*3600 + int(x[3:5])*60)/86400)\n",
    "dataset_AQI_Weather['sunset'] = dataset_AQI_Weather['sunset'].apply(lambda x: (int(x[:2])*3600 + int(x[3:5])*60)/86400)\n",
    "\n",
    "#make new column Datetime from index\n",
    "dataset_AQI_Weather['Datetime'] = dataset_AQI_Weather.index\n",
    "\n",
    "#make columns 'hour', 'day', 'month', 'year' from Datetime\n",
    "dataset_AQI_Weather['hour'] = dataset_AQI_Weather['Datetime'].apply(lambda x: sin_cos(x[11:13],mode = 'hour'))\n",
    "dataset_AQI_Weather['day'] = dataset_AQI_Weather['Datetime'].apply(lambda x: sin_cos(x[8:10], mode = 'day'))\n",
    "dataset_AQI_Weather['month'] = dataset_AQI_Weather['Datetime'].apply(lambda x: sin_cos(x[5:7], mode = 'month'))\n",
    "\n",
    "#apply deg2rad to columns 'winddirDegree'\n",
    "dataset_AQI_Weather['winddirDegree'] = dataset_AQI_Weather['winddirDegree'].apply(deg2rad)\n",
    "\n",
    "#drop Datetime column\n",
    "dataset_AQI_Weather.drop('Datetime', axis=1, inplace=True)\n",
    "\n",
    "#use minmax scaler on dataset_AQI_Weather\n",
    "dataset_AQI_Weather = pd.DataFrame(scaler.fit_transform(dataset_AQI_Weather), columns=dataset_AQI_Weather.columns, index=dataset_AQI_Weather.index)\n",
    "\n",
    "#make 'AQI' as the target variable\n",
    "dataset_y = dataset_AQI_Weather['AQI']\n",
    "dataset_x = dataset_AQI_Weather#.drop(['AQI', 'PM2.5', 'PM10'], axis=1)\n",
    "\n",
    "#shift dataset_y by 24\n",
    "dataset_y = dataset_y.shift(-24)\n",
    "\n",
    "#drop the last 24 rows of dataset_x and dataset_y\n",
    "dataset_x = dataset_x.drop(dataset_x.index[-24:])\n",
    "dataset_y = dataset_y.drop(dataset_y.index[-24:])\n",
    "\n",
    "#make dataframe dataset_test where index contains '2019'\n",
    "dataset_test_y = dataset_y[dataset_y.index.str.contains('2019')]\n",
    "dataset_test_x = dataset_x[dataset_x.index.str.contains('2019')]\n",
    "\n",
    "#remove rows where '2019' is in index in dataset_x and dataset_y\n",
    "dataset_y = dataset_y[~dataset_y.index.str.contains('2019')]\n",
    "dataset_x = dataset_x[~dataset_x.index.str.contains('2019')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to train a neural network on dataset_x and dataset_y\n",
    "def train_model(dataset_x, dataset_y, dataset_test_x):\n",
    "    #create a neural network\n",
    "    model = Sequential()\n",
    "    #add a layer with 100 neurons\n",
    "    model.add(Dense(100, input_dim=dataset_x.shape[1], activation='relu'))\n",
    "    #add a layer with 50 neurons\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    #add a layer with 25 neurons\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    #add a layer with 10 neurons\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    #add a layer with 1 neuron\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    #compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    #fit the model on the training set\n",
    "    model.fit(dataset_x, dataset_y, epochs=10, batch_size=1, verbose=1)\n",
    "    #make predictions on the test set\n",
    "    predictions = model.predict(dataset_test_x)\n",
    "    #return the model\n",
    "    return model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, predictions = train_model(dataset_x, dataset_y, dataset_test_x)\n",
    "#save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(predictions.shape[0])\n",
    "plt.figure(figsize=(100,20))\n",
    "plt_x = dataset_test_x.index.values\n",
    "plt.plot(plt_x, predictions, c='red', label = 'predictions')\n",
    "plt.plot(plt_x, dataset_test_y, c='blue', label = 'ground truth')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the accuracy of the predictions against dataset_test_y\n",
    "accuracy = mean_squared_error(dataset_test_y, predictions)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
